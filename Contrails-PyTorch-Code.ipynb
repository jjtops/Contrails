{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Modules","metadata":{"_uuid":"25a8a372-dd1d-43e0-958f-8933e4a905a3","_cell_guid":"05f0c987-0246-4a48-8d41-2092d39363c9","trusted":true}},{"cell_type":"markdown","source":"### Imports","metadata":{"_uuid":"a7da9a28-a799-422b-a11c-9b862841e851","_cell_guid":"ba3e553e-8aee-46f7-bd33-7409ffea52eb","trusted":true}},{"cell_type":"code","source":"import torch \nimport torchvision\nimport os \t\nimport torchvision.datasets as datasets \nfrom torch.utils.data import DataLoader \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom tqdm import tqdm","metadata":{"_uuid":"ef222bfd-a216-4f9e-a1d4-f3a7b91f683d","_cell_guid":"94db2a8f-fbd5-4df2-a489-c028523bb7e3","execution":{"iopub.status.busy":"2023-09-12T00:29:41.813151Z","iopub.execute_input":"2023-09-12T00:29:41.81373Z","iopub.status.idle":"2023-09-12T00:29:47.54264Z","shell.execute_reply.started":"2023-09-12T00:29:41.813688Z","shell.execute_reply":"2023-09-12T00:29:47.541581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### head","metadata":{}},{"cell_type":"code","source":"class SegmentationHead(nn.Sequential):\n    def __init__(self, in_channels, out_channels, kernel_size=3, activation=None, upsampling=1):\n        conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n        upsampling = nn.Upsample(scale_factor=upsampling, mode='bilinear', align_corners=False) if upsampling > 1 else nn.Identity()\n        activation = Activation(activation)\n        super().__init__(conv2d, upsampling, activation)","metadata":{"_uuid":"aa258ee5-0bcc-4d4f-98c9-b0f97cf30910","_cell_guid":"04f11ff5-8545-4728-8c02-cf6898d57f62","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:03.133298Z","iopub.execute_input":"2023-09-12T00:30:03.133698Z","iopub.status.idle":"2023-09-12T00:30:03.140346Z","shell.execute_reply.started":"2023-09-12T00:30:03.133667Z","shell.execute_reply":"2023-09-12T00:30:03.139147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### base/module","metadata":{"_uuid":"724c5ec7-2d42-44e1-80b4-c4646269a722","_cell_guid":"82e8a2dc-f528-437b-986b-718af0c2c378","trusted":true}},{"cell_type":"code","source":"class Conv2dReLU(nn.Sequential):\n    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1, use_batchnorm=True):\n        conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=not use_batchnorm)\n        relu = nn.ReLU(inplace=True)\n        bn = nn.BatchNorm2d(out_channels) if use_batchnorm else nn.Identity()\n        super(Conv2dReLU, self).__init__(conv, bn, relu)\nclass Activation(nn.Module):\n    def __init__(self, name, **params):\n        super().__init()\n        if name is None or name == \"identity\":\n            self.activation = nn.Identity(**params)\n        elif name == \"sigmoid\":\n            self.activation = nn.Sigmoid()\n\n    def forward(self, x):\n        return self.activation(x)","metadata":{"_uuid":"772f0a4a-9ad5-45b3-b272-cdeb4b2cbcd2","_cell_guid":"01bdaf30-ff73-487e-b7bf-14461355d2b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:08.105179Z","iopub.execute_input":"2023-09-12T00:30:08.106079Z","iopub.status.idle":"2023-09-12T00:30:08.119421Z","shell.execute_reply.started":"2023-09-12T00:30:08.106031Z","shell.execute_reply":"2023-09-12T00:30:08.118266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{"_uuid":"49c0c6f8-2a80-4bb6-86c7-e864b8fe1de6","_cell_guid":"60b5be01-9d99-42e4-903b-96f3ad958af4","trusted":true}},{"cell_type":"code","source":"import yaml\ncfg = yaml.safe_load(\"\"\"\n\nmodel:\n  encoder: resnest26d.gluon_in1k  \n  pretrained: True   \n  decoder_channels: [256, 128, 64, 32, 16]\n\n\"\"\")","metadata":{"_uuid":"9962b256-707e-4260-9adc-e6e7f9f809cf","_cell_guid":"bc1cd6d0-a32a-4883-9a70-72f2eb8ea1b6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:10.108287Z","iopub.execute_input":"2023-09-12T00:30:10.108792Z","iopub.status.idle":"2023-09-12T00:30:10.127403Z","shell.execute_reply.started":"2023-09-12T00:30:10.108753Z","shell.execute_reply":"2023-09-12T00:30:10.126475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unet","metadata":{"_uuid":"4c08f4b3-f89f-41a3-8913-2fe7617f83f2","_cell_guid":"5c129b80-b277-4e16-bd90-30c9ceceddc6","trusted":true}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, in_channels, skip_channels, out_channels, use_batchnorm=True, dropout=0):\n        super().__init()\n        conv_in_channels = in_channels + skip_channels\n        self.conv1 = Conv2dReLU(conv_in_channels, out_channels, kernel_size=3, padding=1, use_batchnorm=use_batchnorm)\n        self.conv2 = Conv2dReLU(out_channels, out_channels, kernel_size=3, padding=1, use_batchnorm=use_batchnorm)\n        self.dropout_skip = nn.Dropout(p=dropout)\n\n    def forward(self, x, skip=None):\n        x = F.interpolate(x, scale_factor=2, mode='nearest')\n        if skip is not None:\n            skip = self.dropout_skip(skip)\n            x = torch.cat([x, skip], dim=1)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n\nclass UnetDecoder(nn.Module):\n    def __init__(self, encoder_channels, decoder_channels, use_batchnorm=True, dropout=0):\n        super().__init()\n        encoder_channels = encoder_channels[::-1]\n        head_channels = encoder_channels[0]\n        in_channels = [head_channels] + list(decoder_channels[:-1])\n        skip_channels = list(encoder_channels[1:]) + [0]\n        out_channels = decoder_channels\n        self.center = nn.Identity()\n        blocks = [\n            DecoderBlock(in_ch, skip_ch, out_ch, use_batchnorm=use_batchnorm, dropout=dropout)\n            for in_ch, skip_ch, out_ch in zip(in_channels, skip_channels, out_channels)\n        ]\n        self.blocks = nn.ModuleList(blocks)\n\n    def forward(self, features):\n        features = features[::-1]\n        head = features[0]\n        skips = features[1:]\n        x = self.center(head)\n        for i, decoder_block in enumerate(self.blocks):\n            skip = skips[i] if i < len(skips) else None\n            x = decoder_block(x, skip)\n        return x","metadata":{"_uuid":"55ddd8be-05a3-4fea-84c4-2e66c6304c02","_cell_guid":"da4484cb-57c1-4dd3-acb3-db8d79728047","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:12.617953Z","iopub.execute_input":"2023-09-12T00:30:12.618334Z","iopub.status.idle":"2023-09-12T00:30:12.632346Z","shell.execute_reply.started":"2023-09-12T00:30:12.618282Z","shell.execute_reply":"2023-09-12T00:30:12.631174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## timm-resnest26d + unet","metadata":{"_uuid":"534e81c0-6ae3-4be6-bccb-b3badb9bceb3","_cell_guid":"f186a1ca-87b1-4712-8c67-99afcd3a2c85","trusted":true}},{"cell_type":"code","source":"class Model(nn.Module):\n\n    def __init__(self, cfg, pretrained, tta=None):\n        super().__init__()\n        name = cfg['model']['encoder']\n        dropout = cfg['model']['dropout']\n        pretrained = pretrained and cfg['model']['pretrained']\n    \n\n        self.encoder = timm.create_model(name, features_only=True, pretrained=pretrained)\n        encoder_channels = self.encoder.feature_info.channels()\n\n\n\n        decoder_channels = cfg['model']['decoder_channels'] \n        print('Encoder channels:', name, encoder_channels)\n        print('Decoder channels:', decoder_channels)\n\n        assert len(encoder_channels) == len(decoder_channels)\n\n        self.decoder = UnetDecoder(\n            encoder_channels=encoder_channels,\n            decoder_channels=decoder_channels,\n            dropout=dropout,\n        )\n\n        self.segmentation_head = SegmentationHead(\n            in_channels=decoder_channels[-1],\n            out_channels=1, activation=\"sigmoid\", kernel_size=3,\n        )\n\n        initialize_decoder(self.decoder)\n\n\n    def forward(self, x):\n\n        features = self.encoder(x)\n        decoder_output = self.decoder(features)\n        y_pred = self.segmentation_head(decoder_output)\n\n\n\n        return y_pred","metadata":{"_uuid":"f00c9aee-9e4e-4cfd-a349-802bc132ed35","_cell_guid":"dce1038a-fa54-47e8-abbd-86d7f2931c8e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:15.282734Z","iopub.execute_input":"2023-09-12T00:30:15.283086Z","iopub.status.idle":"2023-09-12T00:30:15.294784Z","shell.execute_reply.started":"2023-09-12T00:30:15.283057Z","shell.execute_reply":"2023-09-12T00:30:15.293791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-10T13:42:32.956871Z","iopub.execute_input":"2023-09-10T13:42:32.957248Z","iopub.status.idle":"2023-09-10T13:42:33.131005Z","shell.execute_reply.started":"2023-09-10T13:42:32.957216Z","shell.execute_reply":"2023-09-10T13:42:33.129996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset/DataLoader","metadata":{"_uuid":"6fbb4cda-cb9a-4927-a932-97192da2c69a","_cell_guid":"266911b8-ee55-4dbc-bbe4-a52c1b4d0941","trusted":true}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm","metadata":{"_uuid":"4d2c5fd1-62a0-4c8a-a11c-b87eab64bab7","_cell_guid":"8403da04-0299-4427-827d-330848239d2e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-12T00:30:20.053101Z","iopub.execute_input":"2023-09-12T00:30:20.053488Z","iopub.status.idle":"2023-09-12T00:30:20.388899Z","shell.execute_reply.started":"2023-09-12T00:30:20.053453Z","shell.execute_reply":"2023-09-12T00:30:20.387952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Helper function to create fc images\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating class for dataset\nclass ContrailsDataset(Dataset):\n    def __init__(self, path, arr, img_size, train=True, batch_size=16):\n        if train: \n            self.arr = arr\n            self.path = path\n            self.img_size = img_size\n            self.train = train\n            self.batch_size = batch_size\n            self.files = self.arr[0:18_000]\n        \n        else:\n            self.arr = arr\n            self.path = path\n            self.img_size = img_size\n            self.train = train\n            self.batch_size = batch_size\n            self.files = self.arr[0:1624]\n\n            \n    def __len__(self):\n        return len(self.files)\n    \n    \n    \n    \n    def augment(self, path1):\n        #Augmentation to create the false color images\n        self.path1 = path1 \n        _T11_BOUNDS = (243, 303)\n        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n        _TDIFF_BOUNDS = (-4, 2)\n        b11 = np.load(self.path1 + \"/band_11.npy\")\n        b14 = np.load(self.path1 + \"/band_14.npy\")\n        b15 = np.load(self.path1 + \"/band_15.npy\")\n        ma = np.load(path1 + \"/human_pixel_masks.npy\")\n\n        r = normalize_range(b15 - b14, _TDIFF_BOUNDS)\n        g = normalize_range(b14 - b11, _CLOUD_TOP_TDIFF_BOUNDS)\n        b = normalize_range(b14, _T11_BOUNDS)\n        fc = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n        im = fc[..., 4]\n\n        return im, ma\n        \n        \n    def __getitem__(self, index): \n        \n        if self.train:\n            _path = self.path + \"train/\" + self.files[index]\n            img, mask = self.augment(_path)\n            img = img.transpose((2, 0, 1))\n            mask = mask.transpose((2, 0, 1))\n        \n        else:\n            _path = self.path + \"valid/\" + self.files[index]\n            img, mask = self.augment(_path)\n            img = np.transpose(img, (2, 0, 1))\n            mask = mask.transpose((2, 0, 1))\n            \n            \n        return img, mask","metadata":{"_uuid":"9fc99601-5428-45a8-9aee-6ad4c2d94085","_cell_guid":"c27a9e6d-cd92-4668-92b9-a923895c8db4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-11T23:15:50.931984Z","iopub.execute_input":"2023-09-11T23:15:50.932423Z","iopub.status.idle":"2023-09-11T23:15:50.946216Z","shell.execute_reply.started":"2023-09-11T23:15:50.932388Z","shell.execute_reply":"2023-09-11T23:15:50.945034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_data = \"/kaggle/input/google-research-identify-contrails-reduce-global-warming/\"\nimg_size = (256, 256)\nbatch_size = 16\nbatch_size1 = 8\ntrain_id_list = os.listdir(\"/kaggle/input/google-research-identify-contrails-reduce-global-warming/train\")\nvalid_id_list = os.listdir(\"/kaggle/input/google-research-identify-contrails-reduce-global-warming/valid\")\ntrain_ds = ContrailsDataset(path_to_data, train_id_list, img_size, train=True, batch_size=batch_size)\nvalid_ds = ContrailsDataset(path_to_data, valid_id_list, img_size, train=False, batch_size=batch_size1)","metadata":{"_uuid":"53050c32-26ba-4612-b633-32ca13853f94","_cell_guid":"9513af96-6f1f-4e9e-928c-8ca8ecc7bf6c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-11T23:15:54.880038Z","iopub.execute_input":"2023-09-11T23:15:54.880477Z","iopub.status.idle":"2023-09-11T23:15:54.945212Z","shell.execute_reply.started":"2023-09-11T23:15:54.880439Z","shell.execute_reply":"2023-09-11T23:15:54.943876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=cfg['train']['num_workers'], pin_memory=True)\nvalid_loader = DataLoader(valid_ds, batch_size=batch_size1, shuffle=True, num_workers=cfg['train']['num_workers'], pin_memory=True)","metadata":{"_uuid":"d48a8d9d-75df-4fa1-9c10-8f442815ccab","_cell_guid":"774f8bf0-b280-40a1-a424-f7167b1fde67","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-11T23:16:14.675888Z","iopub.execute_input":"2023-09-11T23:16:14.676331Z","iopub.status.idle":"2023-09-11T23:16:14.683391Z","shell.execute_reply.started":"2023-09-11T23:16:14.676298Z","shell.execute_reply":"2023-09-11T23:16:14.6819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Train/Valid Images","metadata":{}},{"cell_type":"code","source":"img, mask  = next(iter(train_loader))\nimg1, mask1 =  next(iter(valid_loader))","metadata":{"_uuid":"9d69b909-b19d-494e-a212-ed1eb3fd9129","_cell_guid":"42f94388-6090-47d0-a790-0a8d6f6ea1eb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-30T14:57:42.278266Z","iopub.execute_input":"2023-08-30T14:57:42.278648Z","iopub.status.idle":"2023-08-30T14:57:42.726413Z","shell.execute_reply.started":"2023-08-30T14:57:42.278618Z","shell.execute_reply":"2023-08-30T14:57:42.725439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show(img):\n    im = img[0]\n    im = im.numpy()\n    im = im.transpose((1,2,0))\n\nprep_img = show(img)\nplt.imshow(prep_img, interpolation='none')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T00:37:43.15933Z","iopub.execute_input":"2023-09-04T00:37:43.160265Z","iopub.status.idle":"2023-09-04T00:37:43.165147Z","shell.execute_reply.started":"2023-09-04T00:37:43.160233Z","shell.execute_reply":"2023-09-04T00:37:43.163982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss/Accuracy -->  Dice","metadata":{"_uuid":"07909ea0-f293-431b-bf4b-32f824d962be","_cell_guid":"f68eded0-54a5-4135-a2da-7023d94fa5b7","trusted":true}},{"cell_type":"code","source":"#dice coef/loss\ndef dice_coeff(y_true, y_pred):\n    y_true=y_true.to(device)\n    y_pred = y_pred.to(device)\n    smooth = 1e-5\n    intersection = torch.sum(y_true * y_pred)\n    union = torch.sum(y_true) + torch.sum(y_pred)\n    dice = (2.0 * intersection + smooth) / (union + smooth)\n    return dice\n\nclass DiceLoss(torch.nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, y_true, y_pred):\n        return 1.0 - dice_coeff(y_true, y_pred)","metadata":{"_uuid":"6178c07a-6fe6-442e-b0aa-1c4d11deeec8","_cell_guid":"f89626ef-34e6-4d34-99ef-8b508e34e311","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-11T23:17:19.30466Z","iopub.execute_input":"2023-09-11T23:17:19.305092Z","iopub.status.idle":"2023-09-11T23:17:19.315038Z","shell.execute_reply.started":"2023-09-11T23:17:19.305058Z","shell.execute_reply":"2023-09-11T23:17:19.312879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"_uuid":"f060b389-f91f-42fa-a8a8-fc98bd47f313","_cell_guid":"044e32e4-cffd-4511-9623-38edc8b35b0f","trusted":true}},{"cell_type":"code","source":"#Setting up the model params// can be run on parallel gpu if needed\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbest_val=0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = DiceLoss()\nnum_epochs = 60\n\nfor epoch in range(num_epochs): \n\n    model.to(device)\n       \n    model.train()\n    epoch_loss = 0\n    dice_score = 0\n    total_batches = len(train_loader)\n    \n    loop = tqdm(enumerate(train_loader), total=total_batches, leave=False)\n    \n    for batch_idx, (img, mask) in loop: \n\n        optimizer.zero_grad()\n        img = img.to(device)\n        mask = mask.to(device)\n        \n        masks_pred = model(img)\n        \n        loss = criterion(mask, masks_pred)\n        dice = dice_coeff(mask, masks_pred)\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        dice_score += dice.item()\n        \n        loop.set_description(f\"Epoch[{epoch+1}/{num_epochs}]\")\n        loop.set_postfix(loss=loss.item(), dice_coeff=dice.item())\n    \n\n    #Calculate and print average loss and dice coefficient for the epoch\n    avg_epoch_loss = epoch_loss / total_batches\n    avg_dice_score = dice_score / total_batches\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {avg_epoch_loss:.4f} - Average Dice Coefficient: {avg_dice_score:.4f}\")\n    torch.save(model.state_dict(), 'cont_best_model.pth')\n    model.eval()\n    val_dice=0\n\n    loop2 = tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False)\n    \n    with torch.no_grad():\n        for batch_idx, (v_img,v_mask) in loop2:\n            v_img, v_mask = v_img.to(device), v_mask.to(device)        \n            v_out = model(v_img)\n            dice = dice_coeff(v_mask, v_out)\n            val_dice += dice.item()\n            \n    average_dice = val_dice / len(valid_loader)\n## Code for saving models with the best validation score\n#     if best_val<average_dice:\n#         best_val = average_dice\n#         checkpoint = {\n#             'epoch': epoch,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict()\n#         }\n#         torch.save(model.state_dict(), 'cont_best_model.pth')\n#         print(\"Model has been saved\")\n    print(f\"Validation Dice Coefficient: {average_dice}\")\n        ","metadata":{"_uuid":"7a31b538-a7a3-486b-bde0-6ccdab4b8722","_cell_guid":"24238bd8-dc53-4191-afe2-df2363c163dc","collapsed":false,"jupyter":{"outputs_hidden":false},"scrolled":true,"execution":{"iopub.status.busy":"2023-09-10T23:50:55.10989Z","iopub.execute_input":"2023-09-10T23:50:55.110238Z","iopub.status.idle":"2023-09-10T23:57:03.544917Z","shell.execute_reply.started":"2023-09-10T23:50:55.110212Z","shell.execute_reply":"2023-09-10T23:57:03.543697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-10T03:09:25.374405Z","iopub.execute_input":"2023-09-10T03:09:25.374971Z","iopub.status.idle":"2023-09-10T03:09:25.381319Z","shell.execute_reply.started":"2023-09-10T03:09:25.374931Z","shell.execute_reply":"2023-09-10T03:09:25.37999Z"},"trusted":true},"execution_count":null,"outputs":[]}]}